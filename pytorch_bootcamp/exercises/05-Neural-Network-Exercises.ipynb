{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../Pierian-Data-Logo.PNG\">\n",
    "<br>\n",
    "<strong><center>Copyright 2019. Created by Jose Marcial Portilla.</center></strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Neural Network Exercises\n",
    "For these exercises we'll perform a binary classification on the Census Income dataset available from the <a href = 'http://archive.ics.uci.edu/ml/datasets/Adult'>UC Irvine Machine Learning Repository</a><br>\n",
    "The goal is to determine if an individual earns more than $50K based on a set of continuous and categorical variables.\n",
    "\n",
    "<div class=\"alert alert-danger\" style=\"margin: 10px\"><strong>IMPORTANT NOTE!</strong> Make sure you don't run the cells directly above the example output shown, <br>otherwise you will end up writing over the example output!</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Census Income Dataset\n",
    "For this exercises we're using the Census Income dataset available from the <a href='http://archive.ics.uci.edu/ml/datasets/Adult'>UC Irvine Machine Learning Repository</a>.\n",
    "\n",
    "The full dataset has 48,842 entries. For this exercise we have reduced the number of records, fields and field entries, and have removed entries with null values. The file <strong>income.csv</strong> has\t30,000 entries\n",
    "\n",
    "Each entry contains the following information about an individual:\n",
    "* <strong>age</strong>: the age of an individual as an integer from 18 to 90 (continuous)\n",
    "* <strong>sex</strong>: Male or Female (categorical)\n",
    "* <strong>education</strong>: represents the highest level of education achieved by an individual (categorical)\n",
    "* <strong>education_num</strong>: represents education as an integer from 3 to 16 (categorical)\n",
    "<div><table style=\"display: inline-block\">\n",
    "<tr><td>3</td><td>5th-6th</td><td>8</td><td>12th</td><td>13</td><td>Bachelors</td></tr>\n",
    "<tr><td>4</td><td>7th-8th</td><td>9</td><td>HS-grad</td><td>14</td><td>Masters</td></tr>\n",
    "<tr><td>5</td><td>9th</td><td>10</td><td>Some-college</td><td>15</td><td>Prof-school</td></tr>\n",
    "<tr><td>6</td><td>10th</td><td>11</td><td>Assoc-voc</td><td>16</td><td>Doctorate</td></tr>\n",
    "<tr><td>7</td><td>11th</td><td>12</td><td>Assoc-acdm</td></tr>\n",
    "</table></div>\n",
    "* <strong>marital-status</strong>: marital status of an individual (categorical)\n",
    "<div><table style=\"display: inline-block\">\n",
    "<tr><td>Married</td><td>Divorced</td><td>Married-spouse-absent</td></tr>\n",
    "<tr><td>Separated</td><td>Widowed</td><td>Never-married</td></tr>\n",
    "</table></div>\n",
    "* <strong>workclass</strong>: a general term to represent the employment status of an individual (categorical)\n",
    "<div><table style=\"display: inline-block\">\n",
    "<tr><td>Local-gov</td><td>Private</td></tr>\n",
    "<tr><td>State-gov</td><td>Self-emp</td></tr>\n",
    "<tr><td>Federal-gov</td></tr>\n",
    "</table></div>\n",
    "* <strong>occupation</strong>: the general type of occupation of an individual (categorical)\n",
    "<div><table style=\"display: inline-block\">\n",
    "<tr><td>Adm-clerical</td><td>Handlers-cleaners</td><td>Protective-serv</td></tr>\n",
    "<tr><td>Craft-repair</td><td>Machine-op-inspct</td><td>Sales</td></tr>\n",
    "<tr><td>Exec-managerial</td><td>Other-service</td><td>Tech-support</td></tr>\n",
    "<tr><td>Farming-fishing</td><td>Prof-specialty</td><td>Transport-moving</td></tr>\n",
    "</table></div>\n",
    "* <strong>hours-per-week</strong>: the hours an individual has reported to work per week as an integer from 20 to 90 (continuous)\n",
    "* <strong>income</strong>: whether or not an individual makes more than \\\\$50,000 annually (label)\n",
    "* <strong>label</strong>: income represented as an integer (0: <=\\\\$50K, 1: >\\\\$50K) (optional label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform standard imports\n",
    "Run the cell below to load the libraries needed for this exercise and the Census Income dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('../Data/income.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>workclass</th>\n",
       "      <th>occupation</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>income</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>Male</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Private</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>Male</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Married</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>50</td>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59</td>\n",
       "      <td>Male</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Self-emp</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>20</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>Female</td>\n",
       "      <td>Prof-school</td>\n",
       "      <td>15</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Federal-gov</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>57</td>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>Female</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Private</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex    education  education-num marital-status    workclass  \\\n",
       "0   27    Male      HS-grad              9  Never-married      Private   \n",
       "1   47    Male      Masters             14        Married    Local-gov   \n",
       "2   59    Male      HS-grad              9       Divorced     Self-emp   \n",
       "3   38  Female  Prof-school             15  Never-married  Federal-gov   \n",
       "4   64  Female         11th              7        Widowed      Private   \n",
       "\n",
       "        occupation  hours-per-week income  label  \n",
       "0     Craft-repair              40  <=50K      0  \n",
       "1  Exec-managerial              50   >50K      1  \n",
       "2   Prof-specialty              20  <=50K      0  \n",
       "3   Prof-specialty              57   >50K      1  \n",
       "4  Farming-fishing              40  <=50K      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    21700\n",
       "1     8300\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Separate continuous, categorical and label column names\n",
    "You should find that there are 5 categorical columns, 2 continuous columns and 1 label.<br>\n",
    "In the case of <em>education</em> and <em>education-num</em> it doesn't matter which column you use. For the label column, be sure to use <em>label</em> and not <em>income</em>.<br>\n",
    "Assign the variable names \"cat_cols\", \"cont_cols\" and \"y_col\" to the lists of names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'sex', 'education', 'education-num', 'marital-status',\n",
       "       'workclass', 'occupation', 'hours-per-week', 'income', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat_cols  has 5 columns\n",
      "cont_cols has 2 columns\n",
      "y_col     has 1 column\n"
     ]
    }
   ],
   "source": [
    "# CODE HERE\n",
    "\n",
    "cat_cols = [\"sex\", \"education\", \"marital-status\", \"workclass\", \"occupation\"]\n",
    "cont_cols = [\"age\", \"hours-per-week\"]\n",
    "y_col = [\"label\"]\n",
    "\n",
    "# RUN THIS CODE TO COMPARE RESULTS:\n",
    "print(f'cat_cols  has {len(cat_cols)} columns')\n",
    "print(f'cont_cols has {len(cont_cols)} columns')\n",
    "print(f'y_col     has {len(y_col)} column')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat_cols  has 5 columns\n",
      "cont_cols has 2 columns\n",
      "y_col     has 1 column\n"
     ]
    }
   ],
   "source": [
    "# DON'T WRITE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Convert categorical columns to category dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                  int64\n",
       "sex               category\n",
       "education         category\n",
       "education-num        int64\n",
       "marital-status    category\n",
       "workclass         category\n",
       "occupation        category\n",
       "hours-per-week       int64\n",
       "income              object\n",
       "label                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CODE HERE\n",
    "\n",
    "for col in cat_cols:\n",
    "    df[col] = df[col].astype('category')\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T WRITE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Shuffle the dataset\n",
    "The <strong>income.csv</strong> dataset is already shuffled. However, if you would like to try different configurations after completing the exercises, this is where you would want to shuffle the entire set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS CELL IS OPTIONAL\n",
    "df = shuffle(df, random_state=101)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Set the embedding sizes\n",
    "Create a variable \"cat_szs\" to hold the number of categories in each variable.<br>\n",
    "Then create a variable \"emb_szs\" to hold the list of (category size, embedding size) tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['10th', '11th', '12th', '5th-6th', '7th-8th', '9th', 'Assoc-acdm',\n",
       "       'Assoc-voc', 'Bachelors', 'Doctorate', 'HS-grad', 'Masters',\n",
       "       'Prof-school', 'Some-college'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[cat_cols[1]].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 1), (14, 7), (6, 3), (5, 3), (12, 6)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CODE HERE\n",
    "\n",
    "cat_szs = [len(df[col].cat.categories) for col in cat_cols]\n",
    "emb_szs = [(cat_sz, min(50, (cat_sz+1)//2) for cat_sz in cat_szs]\n",
    "emb_szs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 1), (14, 7), (6, 3), (5, 3), (12, 6)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DON'T WRITE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create an array of categorical values\n",
    "Create a NumPy array called \"cats\" that contains a stack of each categorical column <tt>.cat.codes.values</tt><br>\n",
    "Note: your output may contain different values. Ours came after performing the shuffle step shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1, 10,  3,  2,  1],\n",
       "       [ 1, 11,  1,  1,  2],\n",
       "       [ 1, 10,  0,  3,  7],\n",
       "       [ 0, 12,  3,  0,  7],\n",
       "       [ 0,  1,  5,  2,  3]], dtype=int8)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CODE HERE\n",
    "\n",
    "cats = np.stack([df[cat].cat.codes.values for cat in cat_cols], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# RUN THIS CODE TO COMPARE RESULTS\n",
    "cats[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1, 10,  3,  2,  1],\n",
       "       [ 1, 11,  1,  1,  2],\n",
       "       [ 1, 10,  0,  3,  7],\n",
       "       [ 0, 12,  3,  0,  7],\n",
       "       [ 0,  1,  5,  2,  3]], dtype=int8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DON'T WRITE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Convert \"cats\" to a tensor\n",
    "Convert the \"cats\" NumPy array to a tensor of dtype <tt>int64</tt>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1, 10,  3,  2,  1],\n",
       "        [ 1, 11,  1,  1,  2],\n",
       "        [ 1, 10,  0,  3,  7],\n",
       "        ...,\n",
       "        [ 1, 12,  1,  2,  7],\n",
       "        [ 0, 13,  3,  2,  0],\n",
       "        [ 1,  6,  1,  3,  2]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CODE HERE\n",
    "cats = torch.tensor(cats, dtype=torch.int64)\n",
    "cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T WRITE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Create an array of continuous values\n",
    "Create a NumPy array called \"conts\" that contains a stack of each continuous column.<br>\n",
    "Note: your output may contain different values. Ours came after performing the shuffle step shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27, 40],\n",
       "       [47, 50],\n",
       "       [59, 20],\n",
       "       [38, 57],\n",
       "       [64, 40]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CODE HERE\n",
    "conts = np.stack([df[col].values for col in cont_cols], axis=1)\n",
    "\n",
    "# RUN THIS CODE TO COMPARE RESULTS\n",
    "conts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27, 40],\n",
       "       [47, 50],\n",
       "       [59, 20],\n",
       "       [38, 57],\n",
       "       [64, 40]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DON'T WRITE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Convert \"conts\" to a tensor\n",
    "Convert the \"conts\" NumPy array to a tensor of dtype <tt>float32</tt>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CODE HERE\n",
    "conts = torch.tensor(conts, dtype=torch.float32)\n",
    "\n",
    "# RUN THIS CODE TO COMPARE RESULTS\n",
    "conts.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DON'T WRITE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Create a label tensor\n",
    "Create a tensor called \"y\" from the values in the label column. Be sure to flatten the tensor so that it can be passed into the CE Loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0,  ..., 1, 0, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CODE HERE\n",
    "y = torch.tensor(df[y_col].values.flatten())\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T WRITE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Create train and test sets from <tt>cats</tt>, <tt>conts</tt>, and <tt>y</tt>\n",
    "We use the entire batch of 30,000 records, but a smaller batch size will save time during training.<br>\n",
    "We used a test size of 5,000 records, but you can choose another fixed value or a percentage of the batch size.<br>\n",
    "Make sure that your test records remain separate from your training records, without overlap.<br>\n",
    "To make coding slices easier, we recommend assigning batch and test sizes to simple variables like \"b\" and \"t\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1, 10,  3,  2,  1],\n",
       "        [ 1, 11,  1,  1,  2],\n",
       "        [ 1, 10,  0,  3,  7],\n",
       "        ...,\n",
       "        [ 1, 12,  1,  2,  7],\n",
       "        [ 0, 13,  3,  2,  0],\n",
       "        [ 1,  6,  1,  3,  2]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE HERE\n",
    "batch_size = 30000 # suggested batch size\n",
    "test_size = 5000  # suggested test size\n",
    "\n",
    "cat_train = cats[:batch_size-test_size]\n",
    "cat_test = cats[batch_size-test_size:]\n",
    "con_train = conts[:batch_size-test_size]\n",
    "con_test = conts[batch_size-test_size:]\n",
    "y_train = y[:batch_size-test_size]\n",
    "y_test = y[batch_size-test_size:batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T WRITE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model class\n",
    "Run the cell below to define the TabularModel model class we've used before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularModel(nn.Module):\n",
    "\n",
    "    def __init__(self, emb_szs, n_cont, out_sz, layers, p=0.5):\n",
    "        # Call the parent __init__\n",
    "        super().__init__()\n",
    "        \n",
    "        # Set up the embedding, dropout, and batch normalization layer attributes\n",
    "        self.embeds = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs])\n",
    "        self.emb_drop = nn.Dropout(p)\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "        \n",
    "        # Assign a variable to hold a list of layers\n",
    "        layerlist = []\n",
    "        \n",
    "        # Assign a variable to store the number of embedding and continuous layers\n",
    "        n_emb = sum((nf for ni,nf in emb_szs))\n",
    "        n_in = n_emb + n_cont\n",
    "        \n",
    "        # Iterate through the passed-in \"layers\" parameter (ie, [200,100]) to build a list of layers\n",
    "        for i in layers:\n",
    "            layerlist.append(nn.Linear(n_in,i)) \n",
    "            layerlist.append(nn.ReLU(inplace=True))\n",
    "            layerlist.append(nn.BatchNorm1d(i))\n",
    "            layerlist.append(nn.Dropout(p))\n",
    "            n_in = i\n",
    "        layerlist.append(nn.Linear(layers[-1],out_sz))\n",
    "        \n",
    "        # Convert the list of layers into an attribute\n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "    \n",
    "    def forward(self, x_cat, x_cont):\n",
    "        # Extract embedding values from the incoming categorical data\n",
    "        embeddings = []\n",
    "        for i,e in enumerate(self.embeds):\n",
    "            embeddings.append(e(x_cat[:,i]))\n",
    "        x = torch.cat(embeddings, 1)\n",
    "        # Perform an initial dropout on the embeddings\n",
    "        x = self.emb_drop(x)\n",
    "        \n",
    "        # Normalize the incoming continuous data\n",
    "        x_cont = self.bn_cont(x_cont)\n",
    "        x = torch.cat([x, x_cont], 1)\n",
    "        \n",
    "        # Set up model layers\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Set the random seed\n",
    "To obtain results that can be recreated, set a torch manual_seed (we used 33)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f1cb25143d8>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CODE HERE\n",
    "torch.manual_seed(33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1e5e64e5e30>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DON'T WRITE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Create a TabularModel instance\n",
    "Create an instance called \"model\" with one hidden layer containing 50 neurons and a dropout layer p-value of 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabularModel(\n",
       "  (embeds): ModuleList(\n",
       "    (0): Embedding(2, 1)\n",
       "    (1): Embedding(14, 7)\n",
       "    (2): Embedding(6, 3)\n",
       "    (3): Embedding(5, 3)\n",
       "    (4): Embedding(12, 6)\n",
       "  )\n",
       "  (emb_drop): Dropout(p=0.4, inplace=False)\n",
       "  (bn_cont): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=22, out_features=50, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.4, inplace=False)\n",
       "    (4): Linear(in_features=50, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CODE HERE\n",
    "model = TabularModel(emb_szs=emb_szs, n_cont=len(cont_cols), out_sz=2, layers=[50], p=0.4)\n",
    "\n",
    "# RUN THIS CODE TO COMPARE RESULTS\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabularModel(\n",
       "  (embeds): ModuleList(\n",
       "    (0): Embedding(2, 1)\n",
       "    (1): Embedding(14, 7)\n",
       "    (2): Embedding(6, 3)\n",
       "    (3): Embedding(5, 3)\n",
       "    (4): Embedding(12, 6)\n",
       "  )\n",
       "  (emb_drop): Dropout(p=0.4)\n",
       "  (bn_cont): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=22, out_features=50, bias=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.4)\n",
       "    (4): Linear(in_features=50, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DON'T WRITE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Define the loss and optimization functions\n",
    "Create a loss function called \"criterion\" using CrossEntropyLoss<br>\n",
    "Create an optimization function called \"optimizer\" using Adam, with a learning rate of 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE HERE\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T WRITE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "Run the cell below to train the model through 300 epochs. Remember, results may vary!<br>\n",
    "After completing the exercises, feel free to come back to this section and experiment with different parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1  loss: 0.81226861\n",
      "epoch:  26  loss: 0.59122103\n",
      "epoch:  51  loss: 0.51452059\n",
      "epoch:  76  loss: 0.46413764\n",
      "epoch: 101  loss: 0.42888233\n",
      "epoch: 126  loss: 0.40092462\n",
      "epoch: 151  loss: 0.37943363\n",
      "epoch: 176  loss: 0.36461926\n",
      "epoch: 201  loss: 0.35019886\n",
      "epoch: 226  loss: 0.33695278\n",
      "epoch: 251  loss: 0.33249414\n",
      "epoch: 276  loss: 0.32157326\n",
      "epoch: 300  loss: 0.31677243\n",
      "\n",
      "Duration: 101 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "epochs = 300\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    i+=1\n",
    "    y_pred = model(cat_train, con_train)\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    # a neat trick to save screen space:\n",
    "    if i%25 == 1:\n",
    "        print(f'epoch: {i:3}  loss: {loss.item():10.8f}')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f'epoch: {i:3}  loss: {loss.item():10.8f}') # print the last line\n",
    "print(f'\\nDuration: {time.time() - start_time:.0f} seconds') # print the time elapsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Plot the Cross Entropy Loss against epochs\n",
    "Results may vary. The shape of the plot is what matters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.8123, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.8009, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.7814, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.7680, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.7542, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.7483, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.7317, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.7227, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.7118, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.7026, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.6934, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.6761, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.6746, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.6636, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.6573, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.6491, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.6432, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.6382, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.6291, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.6201, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.6143, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.6143, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.6096, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.6028, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.5992, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.5912, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.5891, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.5870, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.5761, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.5764, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.5702, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.5664, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.5673, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.5627, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.5594, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.5537, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.5492, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.5498, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.5444, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.5380, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.5421, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.5385, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.5314, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.5303, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.5271, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.5263, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.5243, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.5221, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.5185, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.5160, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.5145, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.5128, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.5120, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.5067, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.5077, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.5031, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.5023, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4989, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4979, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4945, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4913, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4923, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4909, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4837, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4847, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4832, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4830, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4807, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4759, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4784, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4746, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4761, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4683, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4683, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4679, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4641, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4658, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4611, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4611, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4609, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4568, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4540, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4539, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4549, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4503, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4526, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4493, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4458, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4431, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4411, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4426, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4395, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4398, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4391, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4368, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4338, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4358, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4321, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4323, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4306, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4289, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4244, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4260, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4264, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4243, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4250, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4201, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4198, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4172, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4209, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4136, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4152, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4148, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4141, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4093, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4135, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4113, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4079, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4094, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4104, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4089, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4065, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4071, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4044, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4015, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.4009, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3959, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3945, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3997, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3989, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3956, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3917, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3937, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3951, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3926, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3899, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3891, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3932, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3918, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3883, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3891, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3867, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3833, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3857, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3829, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3803, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3844, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3805, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3827, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3793, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3794, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3778, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3814, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3787, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3777, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3754, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3729, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3731, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3725, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3727, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3719, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3726, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3674, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3747, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3731, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3653, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3657, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3655, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3654, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3652, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3629, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3643, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3617, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3649, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3654, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3646, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3604, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3591, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3623, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3592, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3599, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3564, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3549, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3615, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3563, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3579, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3535, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3550, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3540, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3557, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3512, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3523, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3573, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3514, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3516, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3530, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3492, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3524, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3516, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3495, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3502, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3501, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3463, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3495, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3478, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3475, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3450, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3439, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3456, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3454, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3437, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3479, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3416, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3437, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3390, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3438, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3412, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3447, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3430, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3455, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3406, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3443, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3418, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3420, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3371, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3370, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3378, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3396, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3406, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3392, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3394, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3352, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3362, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3368, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3365, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3354, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3331, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3344, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3341, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3321, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3344, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3348, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3337, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3318, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3348, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3356, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3319, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3303, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3311, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3302, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3325, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3323, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3309, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3302, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3265, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3306, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3268, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3273, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3302, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3265, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3265, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3276, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3274, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3269, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3282, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3242, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3227, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3270, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3256, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3241, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3235, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3216, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3217, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3259, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3232, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3216, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3239, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3233, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3203, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3232, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3241, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3226, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3195, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3209, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3212, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3209, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3228, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3239, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3204, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3175, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3189, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3194, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3204, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3167, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3202, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3183, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3198, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3176, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3186, grad_fn=<NllLossBackward0>),\n",
       " tensor(0.3168, grad_fn=<NllLossBackward0>)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3gc5bn+8e+jLlnVliwXuVdkMC7CdINDaIZQTTEkB9IIJATSSOCENFJOICfwC8EkgdCSQw09oYVim44tA8bdyN1yk1zULKs+vz92bYSR5LXj1Uja+3Nde3l3Znb3Ho+tR++8M+9r7o6IiMSuuKADiIhIsFQIRERinAqBiEiMUyEQEYlxKgQiIjEuIegA+ys3N9cHDx4cdAwRkS5l3rx55e6e19q6LlcIBg8eTHFxcdAxRES6FDNb09Y6nRoSEYlxKgQiIjFOhUBEJMapEIiIxDgVAhGRGKdCICIS41QIRERiXMwUgnlrtnHzi0vRsNsiIp8WM4Vg0YZK/jRrBRsqdgUdRUSkU4mZQjBhYA4A89ZsDziJiEjnEtVCYGanmdkyMysxs+tbWT/QzGaa2Qdm9pGZTY1WltF9MkhNjOd9FQIRkU+JWiEws3hgBnA6UAhMN7PCvTa7EXjM3ccDFwN3RitPQnwchw/I4v21KgQiIi1Fs0UwCShx95XuXg88Apy91zYOZIafZwEbopiHCQNzWLShkl0NTdH8GhGRLiWahaA/sK7F6/XhZS39HPiima0Hnge+3doHmdkVZlZsZsVlZWUHHGhkfgZNzc767TsP+DNERLqboDuLpwP3u3sBMBX4u5l9JpO73+XuRe5elJfX6nDaERnQMw2AtdtUCEREdotmISgFBrR4XRBe1tJXgccA3P0dIAXIjVagAT1TAVi3rTZaXyEi0uVEsxDMBUaY2RAzSyLUGfzsXtusBU4CMLNDCBWCAz/3sw956cmkJMapRSAi0kLUCoG7NwJXAy8BSwhdHbTIzG4ys7PCm30f+LqZzQceBi73KN76a2YMyEljnQqBiMgeUZ2q0t2fJ9QJ3HLZT1s8XwwcG80MexvYM00tAhGRFoLuLO5wA3qmsX57rcYcEhEJi7lCMLBnGtV1jWytqQ86iohIpxBzhWB0nwwAlm6sCjiJiEjnEHOF4JC+oRuZF2+sCDiJiEjnEHOFIKdHEv2yUli8oTLoKCIinULMFQKAwn6ZLN6oQiAiArFaCPpmsqKsRoPPiYgQq4WgXyZNzc6yTeowFhGJyUIwpl8WgE4PiYgQo4WgICeVjOQEdRiLiBCjhcDMOEQdxiIiQIwWAgh1GC/ZWElzs4aaEJHYFrOF4PABWeysb9IcxiIS82K2EJxS2IeMlAQeeGdN0FFERAIVs4WgR3ICFxUN4IUFG9mmAehEJIbFbCEAOHFUbxqbnaWb1GksIrErpgvB0LweAKwsqwk4iYhIcGK6EPTJTCEtKZ4VZdVBRxERCUxMF4K4OGNIbg+1CEQkpsV0IQAYmpeuFoGIxLSYLwTD8npQuqNWI5GKSMyK+UIwMj8Ddw1AJyKxK+YLwVFDe2EGs5eVBR1FRCQQMV8IevZI4vCCbGYvVyEQkdgU84UA4MRRecxfv0N3GItITFIhAI4fkYs7zF29LegoIiIdToUAOLR/FkkJcRSrEIhIDFIhAJIT4jm8IIviNRqSWkRijwpBWNHgniwsraC2XvcTiEhsUSEImzS4Jw1NrolqRCTmqBCETRrSk8R443VdRioiMSaqhcDMTjOzZWZWYmbXt7L+NjP7MPxYbmY7opmnPT2SEyga1FP3E4hIzIlaITCzeGAGcDpQCEw3s8KW27j7d919nLuPA/4IPBmtPJE4fmQuSzdVsaVyV5AxREQ6VDRbBJOAEndf6e71wCPA2e1sPx14OIp59mnyiDwAXv+4PMgYIiIdKpqFoD+wrsXr9eFln2Fmg4AhwGttrL/CzIrNrLisLHqnbgr7ZpKbnqR+AhGJKZ2ls/hi4HF3b/XaTXe/y92L3L0oLy8vaiHi4ozjR+TxZkk5zc0ete8REelMolkISoEBLV4XhJe15mICPi202+SRuWyrqWeJJrQXkRgRzUIwFxhhZkPMLInQD/tn997IzEYDOcA7UcwSsUP7ZQFQskWzlolIbIhaIXD3RuBq4CVgCfCYuy8ys5vM7KwWm14MPOLuneJczMBeaZiheYxFJGYkRPPD3f154Pm9lv10r9c/j2aG/ZWcEE9BTiqrylUIRCQ2dJbO4k5lSG66CoGIxAwVglYM6ZXGqvIaOsnZKhGRqFIhaMWQ3B5U1zVSXq0Zy0Sk+9tnITCzHmYWF34+0szOMrPE6EcLzui+mQB899EPqalrDDiNiEh0RdIieB1IMbP+wL+BLwH3RzNU0I4c0pP/njqaN0vK+ffiTUHHERGJqkgKgbn7TuA84E53vwAYE91YwTIzvnrcUDKSEyherfkJRKR7i6gQmNnRwKXAc+Fl8dGL1DnExxnjB+WoEIhItxdJIfgOcAPwVPiGsKHAzOjG6hyOGJTD8i1VVNQ2BB1FRCRq9lkI3H22u5/l7jeHO43L3f2aDsgWuKLBPXGHt0o0LLWIdF+RXDX0kJllmlkPYCGw2Myui3604E0a0pN+WSk8PGdt0FFERKImklNDhe5eCZwDvEBo3oAvRTVVJxEfZ1w8aSBvfFzOmq2601hEuqdICkFi+L6Bc4Bn3b0BiJlbbqdNLADguQUbA04iIhIdkRSCvwCrgR7A6+HZxGJmsP5+2akc1j+LlxdvDjqKiEhURNJZfLu793f3qR6yBpjSAdk6jZML8/lw3Q62VGlSexHpfiLpLM4ys1t3zxlsZr8n1DqIGacd2gd3eOaDDUFHERE56CI5NXQvUAVcGH5UAvdFM1RnMzI/g0lDenL/26tpbGoOOo6IyEEVSSEY5u4/c/eV4ccvgKHRDtbZfOXYIZTuqOXFRRp7SES6l0gKQa2ZHbf7hZkdC9RGL1LndHJhPsN7p/OHVz6mqTlmLpoSkRgQSSG4EphhZqvNbDVwB/CNqKbqhOLjjGtPGsHHW6p5dYmuIBKR7iOSq4bmu/vhwFhgrLuPBz4X9WSd0GmH9iEjOYHXlm4JOoqIyEET8Qxl7l4ZvsMY4HtRytOpJcbHcezwXGYvL9M0liLSbRzoVJV2UFN0ISeMymNjxS4+3lIddBQRkYPiQAtBzP46fMLIPABmLysLOImIyMHRZiEwsyozq2zlUQX068CMnUq/7FRG5qcze7kKgYh0DwltrXD3jI4M0pWcMDKPB95ew876RtKS2vwrFBHpEg701FBMO2Fkb+qbmnmrZGvQUURE/mMqBAdg0pCe5KYn83/vrgk6iojIf0yF4AAkJcRx2dGDmL28jP95YQllVXVBRxIROWCRjD76bTPL6YgwXckXjxrEoF5p3PX6Sm58ekHQcUREDlgkLYJ8YK6ZPWZmp5lZzN5D0FJOjyRmXzeF735+JC8t2sy8NduDjiQickAiGWLiRmAEcA9wOfCxmf3GzIZFOVuX8LXjh5CZksDf31kddBQRkQMSUR+Bh8ZT2BR+NAI5wONmdkt77wu3IJaZWYmZXd/GNhea2WIzW2RmD+1n/sClJSVw1rh+vLhoE1W7GoKOIyKy3yLpI7jWzOYBtwBvAYe5+1XAROD8dt4XD8wATgcKgelmVrjXNiOAG4Bj3X0M8J0D3ZEgnT+hgF0NzTw6d13QUURE9lskLYKewHnufqq7/8PdGwDcvRk4s533TQJKwpPZ1AOPAGfvtc3XgRnuvj38mV1yWM9xA7KZPDKP3720jI83VwUdR0Rkv0TSR/AzoJeZXRO+gmhCi3VL2nlrf6Dlr8jrw8taGgmMNLO3zOxdMzuttQ8ysyt2z5lcVtb5hnYwM35/weEkxBn3vrU66DgiIvslklNDPwEeAHoBucB9ZnbjQfr+BEId0ScC04G7zSx7743c/S53L3L3ory8vIP01QdXXkYyU0b35uXFmzSDmYh0KZGcGvoicER43uKfAUcBX4rgfaXAgBavC8LLWloPPOvuDe6+ClhOqDB0SaeO6UN5db0uJRWRLiWSQrABSGnxOpnP/kBvzVxghJkNMbMk4GLg2b22eZpQawAzyyV0qmhlBJ/dKU0Z3ZseSfFc9/h8Sraor0BEuoZICkEFsMjM7jez+4CFwA4zu93Mbm/rTe7eCFwNvAQsAR5z90VmdpOZnRXe7CVgq5ktBmYC17l7lx3JLT05gb999Uhq6ho5d8bbvL9WLQMR6fxsX1Mumtll7a139wcOaqJ9KCoq8uLi4o78yv1WuqOWM29/gxNH9ea2i8YFHUdEBDOb5+5Fra3b52D67v5A+NTOyPCiZbsvIZXW9c9O5ehhvZi7elvQUURE9imSq4ZOBD4mdHPYncByM5sc5VxdXtGgnqzfXsumil1BRxERaVckfQS/B05x9xPcfTJwKnBbdGN1fUWDQwO23jmrhNIdtQGnERFpWySFINHdl+1+4e7LgcToReoeCvtmkpOWyN/eWcNPnl4YdBwRkTZFUgjmmdlfzezE8ONuoHP31nYCCfFxvHDtZC4/ZjAzl21h3badQUcSEWlVJIXgSmAxcE34sRi4Kpqhuos+WSl8ffJQDLj3rVVBxxERaVW7Vw2FRxCd7+6jgVs7JlL30j87lYuOGMgDb69m7dadTD2sL+dPLAg6lojIHu22CNy9CVhmZgM7KE+3dMPU0fTPSWX28jJ+/uwitlZrjmMR6TwiOTWUQ+jO4lfN7Nndj2gH604yUxJ57fsn8sK1x7OzoYnfvrA06EgiInvs84Yy4CdRTxEDEuPjGJGfwZUnDGXGzBUcPawX503QKSIRCV4kLYKp7j675QOYGu1g3dV3Pz+S8QOz+d+XltHQ1Bx0HBGRiArBya0sO/1gB4kVCfFxXD1lOBsqdvH8go1BxxERabsQmNlVZrYAGGVmH7V4rAIWdFzE7mfKqN4M753O7a9+rFaBiASuvRbBQ8AXCM0h8IUWj4nufmkHZOu24uKMH546ihVlNZx359vc86buMRCR4LRZCNy9wt1Xu/t0QjOJNQAOpOty0v/cyYX5nDm2L+u27+SWF5dSrktKRSQgkYw+ejWwGXgZeC78+FeUc3V7ZsYdl0zgiauOob6pmft057GIBCSSy0e/A4zqyjOHdWbD8tI5+ZB8Hp6zjj6ZKWDGl44aFHQsEYkhkRSCdYSmq5Qo+eJRg/j34s385JlFABTkpDJlVO+AU4lIrIikEKwEZpnZc8CeE9nurrGHDpLjhucysGcatQ1NZKcm8st/LubEkXmYWdDRRCQGRFII1oYfSeGHHGRxccZ9Xz4CgOLV2/jREwv4aH0Fhw/IDjiZiMSCSOYs/sXey8wskgIi+2FYXjoAuenJ/OTpRTzwzmpu7jeWxPhI7vkTETlw7d1Q9maL53/fa/WcqCWKcVmpiZw3oT9Pvl/KeXe+TW19U9CRRKSba+/XzR4tnh+61zqdvI6i35x7GLdddDgLN1Rw2X1zmL28LOhIItKNtVcIvI3nrb2Wgyguzjh3fAG/PucwVpXXcNm9c7j15eU0N+uvXUQOvvbO9Web2bmEikW2mZ0XXm5AVtSTCZccOZDzJ/bnxqcWcvurH7N2aw23XTROVxOJyEHVXiGYDZzV4vkXWqx7PWqJ5FOSE+K5ZdpYCnLSuO2V5YwfmMNlxwwOOpaIdCNtFgJ3/3JHBpG2mRnXnDScD9dt55f/WkxuejJnjO0bdCwR6SZ0bWIXYWbcPn08hw/I5lsPvc/3H5vPtpr6oGOJSDegQtCFZKQk8uDXjuRbU4bxzIelHPvb1/jvpxbgrk5kETlwKgRdTEpiPNedOprnrz2ekwvzeei9tcxctiXoWCLShUUyDPUFZpYRfn6jmT1pZhOiH03aMzI/g99feDj9s1O5+qEPOOF3M6mobQg6loh0QZG0CH7i7lVmdhzweeAe4E+RfLiZnWZmy8ysxMyub2X95WZWZmYfhh9f27/4sS0xPo7/nnoII3qns3bbTu6cWRJ0JBHpgiIpBLvHODgDuMvdnyOCwefMLB6YQWii+0JgupkVtrLpo+4+Lvz4a4S5JeyMsX155urjOG98AX95fSXn3fkWFTvVMhCRyEVSCErN7C/ARcDzZpYc4fsmASXuvtLd64FHgLMPPKq055fnjOG/p45mQWkF1z76ARsraoOOJCJdRCQ/0C8EXgJOdfcdQE/gugje15/QpDa7rQ8v29v5ZvaRmT1uZgNa+yAzu8LMis2suKxM4+60Ji0pgSsmD+OnZxYya1kZU/53FgvWaz4hEdm3SApBX+A5d//YzE4ELuDgjT76T2Cwu48lNCfyA61t5O53uXuRuxfl5eUdpK/unr509GBm/eBEevVI5qoH57Fjp+41EJH2RVIIngCazGw4cBcwAHgogveVhrfdrSC8bA933+ruu2c9+yswMYLPlX0YnNuDGZdOYHPlLqb9+R3OuuNNnnx/fdCxRKSTiqQQNLt7I3Ae8Ed3v45QK2Ff5gIjzGyImSUBFwPPttzAzFp+zlnAkshiy76MG5DNL846lNLttdTUNfK9x+bz/trtQccSkU4okpnGGsxsOvBffDLwXOK+3uTujWZ2NaH+hXjgXndfZGY3AcXu/ixwjZmdBTQC24DLD2AfpA2XHDmQ6ZMGUF3XSNGvXuGZD0qZMDAn6Fgi0slEUgi+DFwJ/NrdV5nZEGDvGcta5e7PA8/vteynLZ7fANwQeVzZX2ZGRkoinz8knyffL2XppiouOmIAEwflMKhXj31/gIh0e/s8NeTui4EfAAvM7FBgvbvfHPVkclBNnzSQ2oYm1m+v5XuPzeeE383i1n8v0zhFIrLvFkH4SqEHgNWEJqUZYGaXubvmJOhCjhuRy/JfnY4Dc1Zt4/F567n9tRKG52cwsGcaY/tnERenCW9EYlEkp4Z+D5zi7ssAzGwk8DC6wqfL2f2D/uhhvZg0pCeLNlTw/cc+pKHJuXrKcMYNyObEUXkkxGssQpFYEsn/+MTdRQDA3ZcTQWexdG7xccaPTh9NY7MzqFcad8ws4Wt/K+bR4nX7frOIdCuRFIJ5ZvZXMzsx/LgbKI52MIm+KaN68+FPTuGZbx3Lfx09CIAXFmwKOJWIdLRITg1dCXwLuCb8+g3gzqglkg6VlRZq3N109qFkpCTw59kreWHBRob3TmdEfkbA6USkI7RbCMIjiM5399HArR0TSYJy5th+zJi5gqsefB+AG884hCOH9OKQvhnqNxDpxtotBO7eFJ5PYKC7r+2oUBKMQ/pmMusHJ7KjtoE/vvoxv3oudKP3N04Yyg2nHxJwOhGJlkhODeUAi8xsDlCze6G7nxW1VBKYwbmhm8x+e/5Yrnn4Ayp3NXDfW6sZkJNGdlroxrSUxPiAU4rIwWT7uqHIzE5obbm7z45Kon0oKiry4mL1VXeU9dt3ctYdb7GtJjSK6Rlj+zLjEs1UKtLVmNk8dy9qbV2bLYLwaKP5e//AD09ZufHgRpTOqiAnjbev/xzbd9bzf++uYcbMFXxh7CZOO7RP0NFE5CBprwfw/wGVrSyvCK+TGJGSGE/frFSuPWkkh/XP4juPfsD1T3zE5Ftmcv9bq2hu1jAVIl1Ze4Ug390X7L0wvGxw1BJJp5WUEMe9lx/BYf2zeHHRJmobmvjdS8s4/paZ/OyZhUHHE5ED1F5ncXY761IPdhDpGvIykvnHlccAsKKsmlNue52y6joeeGcN4wZmc+74goATisj+aq9FUGxmX997oZl9DZgXvUjSVQzLS+fJq47h9eumMGlwT3781EJKtlQFHUtE9lObVw2ZWT7wFFDPJz/4i4Ak4Fx3D2QsAl011DltqtjFGbe/QVpyPI9feQy9M5KB0HwIIhK89q4aiuTy0SnAoeGXi9z9tYOcb7+oEHRe89ft4JK73yUzNZH4OOOw/lnccckE4jW8tUjg/qNC0NmoEHRuC0sr+OaD7+M467bVkpOWSJ+sVL58zGAuPGJA0PFEYtYB3UcgciAO7Z/FrB+ciBnc//ZqFpZWUrKlih8+8RGbK3dx7oT+QOj+BBHpHNQikKhrbGrmh49/xJMflJKcEEdGSiL//u5kevZICjqaSMxQi0AClRAfx83TxlK5q5HK2gY+WLed425+jTH9MvnNuYdpuGuRgKlFIB3u5cWbeXnxJl5evJma+iZ+9oVCLj1yUNCxRLo1tQikUzm5MJ+TC/Mpq6rje499yE+fWUTPtCSWbqoiNz2JS48ctGd+ZRGJPrUIJFDl1XVM+d0squoaMQN3yElLpFd6Ms9dcxzJCRryWuRgaK9FoGmnJFC56cncMm0s35g8lA9+cjK/POdQxhZkU7KlmofeC82FtL2mnvdWbg04qUj3pRaBdDruziV3v8c7K7dS2DeT1KR4Pli7nbevP4k+WSlBxxPpktQikC7FzLh9+niuO3UUa7ftZN6a7TQ7/OujDWyrqaer/fIi0tmpRSCd2kfrdzBvzXYenbuOpZtCA9plpSZy2pg+3DB1NO+u3MbJhfkaxkJkH3TVkHRZYwuyGVuQTY+kBG55aSmXHjmI1VtreLR4HW+WlFO6o5ZTx+Tzx+mhMY3Kqup0+khkP6kQSJdw4RED9oxV5O6Ubq+leM12Jg3uyUuLNnPl/81j2aYqSnfUctLo3vzvBYeTozuXRSKiPgLpcsyM35x3GF8+djB/++okLjt6EK8t3UJ+ZjLfPHEYb5SUc8btb3DyrbN5f+32oOOKdHpR7SMws9OAPwDxwF/d/bdtbHc+8DhwhLu32wGgPgLZW1Ozs3RTJYV9MzEz3iop59aXl7N++07qGpt5/MqjGd5bw1hIbAvkqiEziwdmAKcDhcB0MytsZbsM4FrgvWhlke4tPs4Y0y9rzyQ4xw7P5YmrjuEf3ziGhLg4vnTPHO57axUNTc0BJxXpnKJ5amgSUOLuK929HngEOLuV7X4J3AzsimIWiUEDe6XxwFeOoEdyAr/452LufmMlmyp2ceptr/PNB+dRuqM26IginUI0C0F/YF2L1+vDy/YwswnAAHd/rr0PMrMrzKzYzIrLysoOflLptsb0y+KV753AlFF53PX6Sm5+cSkryqqZvayMK/5WzK6GJgDqG9VakNgVWGexmcUBtwLf39e27n6Xuxe5e1FeXl70w0m38/1TRlFT18hTH5QybWIBt08fz6INlfz6uSX86l+LOfRnL/HzZxftuVltYWkFW6vrAk4t0jGiefloKdBybsKC8LLdMgjNhTwrfG63D/CsmZ21rw5jkf11aP8s/vXt43l07jquPGEovTNT+OJRA/n7u2sAmDAwm/vfXg3AeRP6c86Mt0hLSuD3Fx7OqWP6BJhcJPqidtWQmSUAy4GTCBWAucAl7r6oje1nAT/QVUPSUarrGvnpMws5c2xfpozqza+fW8Jf31xFckIcWamJ5GemsKq8hrPH9eNzo3tz0iH5QUcWOWCB3Fns7o1mdjXwEqHLR+9190VmdhNQ7O7PRuu7RSKRnpzArReO2/P6x2ccwoj8dJ5fsImvHDeEYXk9OPOPb/LI3HU8PGctt100juG908nLSKZ3hu5elu5DYw2JtKOmrpFmd772QDEfrNtBU7PTJzOFf1x5NPe8uYpBvdKYNrGAODNSEjV3gnRe7bUIVAhEIlBWVcc5M96if04qSzZUkpQQx9aaeuLjjJy0RPpnp/LYlUeTnBDPiws3UtvQxLnjC4KOLbKHBp0T+Q/lZSQz8wcnkhhvFK/ZzpfueY/Cvplsq6mnsbmZ+esrmPK7WYwtyOaVJZtpbHZWldXwleOGkJ2mMY+kc1OLQOQArNu2k8yURJrdSUqI45kPNzBr2RZmLS+jZ1oS4wZk8+KiTfTOSObBrx3JiHwNcSHB0qkhkQ6yYUct8XFGfmYKH6zdzhV/n0dTs3PT2WPo1SOZvlkppCXHk52aRGNzM/+cv4F73lzFj88o5ISRukdGokeFQCQgq8pruPTud9lQ8ekRVFISQ5eoJifEs3bbTpLi45jz45N0GkmiRn0EIgEZktuDF74zmeWbq6ipa6S8up7NlbtYWVbDE++vB2DaxAIen7eelxdv5oKiAfv4RJGDT4VAJMqyUhM5YnDPzyzfWFHLe6u2cf3po3lnxVYemRsamisjJZGs1ESG5Pb41GxrZVV1bK7cxag+GSTGayoROXhUCEQCcsu0sawoqyE3PZkzx/blL6+vZN6aTybSiY8zLj5iAOu211I0KIfbXlmOO+SmJ/PYN45iaF467r5n+G2RA6U+ApFOoLa+icUbK8hNT6a6rpGKnQ3MmFXCWyVbSYgzGpud40fkMm1iATc+tZBxA7P58rGDuf6JBdwybSyTR+QRF2fU1DXym+eX8M0pw+mfnRr0bkknoj4CkU4uNSmeiYM+ffroiCE9WVlWw876Rh6es5YfTy0kKy2RHTsb+Nmzi3izpBx3+PrfijGMOy+dwKbKXTz43lpq65v45pThDMvroRaD7JNaBCJdjLvz5PulvLBwE1dMHspD761hQWkF5dX19EpPYmVZzZ5trzt1FF89bghJ8XG8UVJO0aAcGpudqX94g6tOHMYXjxoU4J5IR9LloyLd3OryGi4JX6b6rSnDmLtqO5W7GlhZVkOTO5kpCWzf2cD5Ewron5PK7a9+TP/sVGZfdyLLN1czsFcaqYnxxBlqQXRTKgQiMWBnfSOzl5Xx+cJ8EuPjWL99J5fc/R5Fg3Ko3NXAroZm3iwpJykhjrz0ZEp31DIqP4Nlm6uYNKQnpdtraWxu5huTh3H6YX2orG1keO904uNUGLoDFQIRoWpXA5fdO4fBuT344amj+cU/F7Gpchd9MlN4YeEmUhLjGD8gh3dWbt3znskj8+iRFI8ZfPtzIxjRO52EvS5d3VZTT21DkzqnOzkVAhFpk7vzv/9exhGDezJ5RB6Pz1tPdV0j5dV13DlrBQCJ8UZDkzOmXyYPfGUSlbUNLNtUxei+mXzrwffZsbOe13845TNFAkJDeW+pqmNIbo+O3jVpQYVARPabu/PDxz+iX3YqFxQVMGtZGb96bjHJCfHsrG+koenTPzu+fvwQRvfJZFCvNOavr2BbTR3PL9hEnMG6bbX88ExoUGkAAAwdSURBVLRRvFlSzi3TxmpinwCoEIjIQbFoQwV/mrWC9OQELjpiAPe/vZqEuDje+LiMLVV1mEGvHkmUV9cDkJGcQJM7jc1OfWPznmWDctN45IqjSU8OXcFeVlXHko2VHD2sl+6ajhLdRyAiB8WYflncccmEPa/HD8wB4LmPNvLhuu08Mncd5dX1fOHwftTWN/GHi8fR2OT85fUVPPjeWm46ewwzl27h6Q83cO+bq/jqcUP48+wV/Hn2ChqanNz0ZHr1SOKey4soyEkLajdjjloEInLQvLBgI4s2VPKDU0d9arm7s6uhmdSk0HSe3/h7MS8v3kxCXBz1Tc2cO74/J4zM49WlW3hl8WbGFmTROzOFZZsq6ZOVynnj+3PW4f2I2+sKpsam5j39EpW7GpizchtHDeu1p6Uhn9CpIRHpVMqq6rj/7VU0NjmnjMn/1F3Vf5q1gptfXEpuemiCn5It1azeupNjhvWirKqOjJQEzh3fn/veXs3KshqOGdaLC4oK+OnTi6iqa+SUwnz+8qWJe+6HqKlrpL6xmey0xJi+R0KFQES6jOZmZ0FpBYX9MkmMj6O52bnrjZXc/OJSjhjck82Vu1izdScFOalMPawvT76/nvLqevpnp3LqmD7c+9YqLj9mMFmpiaQmxXPHayVU1zVSNCiHy48dzOcPyWdlWQ25GUn0zkhhe009yYlxpCV171aECoGIdHk1dY30SE6guq6Rh99by9nj+tE7M4Wt1XXc/cYqpk0sYEhuD258eiEPz1m7532j+2TwhcP7cf/bqymrquOIwTl8tL6CgT3TuOOSCVx81zsU5KTx5DePYWd9E1ur6+iblcqSTZUkJ8Qxpl9WgHt98KgQiEhMWV1eQ3ZaIpsr6xjYM43UpHgampq5981V/M8LS0lOiKOusRkzSEuMp6a+iTH9MinZUr1nuTtkpiTwyvdP4K9vrArNHXHaaI4e1mvP96zZWsPiDZWcfljfAPc2MioEIiKETjv9+vklTByUw+bKXWyq3MUFEwt4fsEmZi8vY2R+BkcMzmHN1p0kJcTxh1c/ZmR+OgtLK/cUj+OG5zL1sL5Mm1jAmX98g+Wbq7nu1FEc2j+L5z7awDHDcjl+RC53vbGS9dtrueL4oRw+IHtPhqZm5+kPSnl35VZumHoIPXt0zPSkKgQiIgfgiXnrufHphWSkJPDcNcfz8Jy1PP1BKSvLa+idkcyWqjoOH5DN/HU7APYUi7yMZLbX1JOWFGpt/ObcQ1m7bSflVfWsLK9m7urQBESfP6Q3d/9XEWbGroYmFpZWMGFgDuu272RAThpN7gftvgoVAhGRA1RWVUdTs++ZNtTdeax4Ha8u2cLEQTl8/fihPDJ3HYs2VPCj00fz/cfm89rSLdxzWRHjB+Zw4Z/fYdnmKhLijOy0ROobm7nxzEKqdzVy078WM21iAZsrd/Hh2h1U1TVy3PBc3iwpZ3SfDFaUVXPpkYPISUvilDH5HNI384D3Q4VARKSDNDY1UxbucAbYsKOWf87fwPkTC8hNT94zvai7c8OTC3hk7joKclI5fkQeGytqmbWsjKF5PSivqmNY73Q+WBtqbSQlxPG7aWM5e1z/A8qlO4tFRDpIQnzcniIA0C87lW+cMGzP6933MpgZvzrnUM4e15+Jg3JISoijYmcDd84q4fJjB9MnM9QCmbNqG70zU7jlxaWM6pMRlcxqEYiIxID2WgQa3UlEJMZFtRCY2WlmtszMSszs+lbWX2lmC8zsQzN708wKo5lHREQ+K2qFwMzigRnA6UAhML2VH/QPufth7j4OuAW4NVp5RESkddFsEUwCStx9pbvXA48AZ7fcwN0rW7zsAXStDgsRkW4gmlcN9QfWtXi9Hjhy743M7FvA94Ak4HNRzCMiIq0IvLPY3We4+zDgR8CNrW1jZleYWbGZFZeVlXVsQBGRbi6ahaAUGNDidUF4WVseAc5pbYW73+XuRe5elJeXdxAjiohINAvBXGCEmQ0xsyTgYuDZlhuY2YgWL88APo5iHhERaUXU+gjcvdHMrgZeAuKBe919kZndBBS7+7PA1Wb2eaAB2A5ctq/PnTdvXrmZrTnAWLlA+QG+t7PRvnRO2pfOSfsCg9pa0eXuLP5PmFlxW3fWdTXal85J+9I5aV/aF3hnsYiIBEuFQEQkxsVaIbgr6AAHkfalc9K+dE7al3bEVB+BiIh8Vqy1CEREZC8qBCIiMS5mCsG+hsTu7MxsdYshu4vDy3qa2ctm9nH4z5ygc7bGzO41sy1mtrDFslazW8jt4eP0kZlNCC75Z7WxLz83s9LwsfnQzKa2WHdDeF+WmdmpwaT+LDMbYGYzzWyxmS0ys2vDy7vccWlnX7ricUkxszlmNj+8L78ILx9iZu+FMz8avkkXM0sOvy4Jrx98QF/s7t3+QeiGthXAUEKD280HCoPOtZ/7sBrI3WvZLcD14efXAzcHnbON7JOBCcDCfWUHpgIvAAYcBbwXdP4I9uXnwA9a2bYw/G8tGRgS/jcYH/Q+hLP1BSaEn2cAy8N5u9xxaWdfuuJxMSA9/DwReC/89/0YcHF4+Z+Bq8LPvwn8Ofz8YuDRA/neWGkR7HNI7C7qbOCB8PMHaGOspqC5++vAtr0Wt5X9bOBvHvIukG1mfTsm6b61sS9tORt4xN3r3H0VUELo32Lg3H2ju78ffl4FLCE0YnCXOy7t7EtbOvNxcXevDr9MDD+c0MjMj4eX731cdh+vx4GTbPekyPshVgpBa0Nit/cPpTNy4N9mNs/Mrggvy3f3jeHnm4D8YKIdkLayd9VjdXX4lMm9LU7RdYl9CZ9OGE/ot88ufVz22hfogsfFzOLN7ENgC/AyoRbLDndvDG/SMu+efQmvrwB67e93xkoh6A6Oc/cJhGZ8+5aZTW650kNtwy55LXBXzh72J2AYMA7YCPw+2DiRM7N04AngO/7piaK63HFpZV+65HFx9yYPzdpYQKilMjra3xkrhWB/h8TudNy9NPznFuApQv9ANu9unof/3BJcwv3WVvYud6zcfXP4P28zcDefnGbo1PtiZomEfnA+6O5Phhd3yePS2r501eOym7vvAGYCRxM6Fbd7kNCWeffsS3h9FrB1f78rVgrBPofE7szMrIeZZex+DpwCLCS0D7tHbL0MeCaYhAekrezPAv8VvkrlKKCixamKTmmvc+XnEjo2ENqXi8NXdgwBRgBzOjpfa8Lnke8Blrh7y7nCu9xxaWtfuuhxyTOz7PDzVOBkQn0eM4Fp4c32Pi67j9c04LVwS27/BN1L3lEPQlc9LCd0vu3HQefZz+xDCV3lMB9YtDs/oXOBrxKax+EVoGfQWdvI/zChpnkDofObX20rO6GrJmaEj9MCoCjo/BHsy9/DWT8K/8fs22L7H4f3ZRlwetD5W+Q6jtBpn4+AD8OPqV3xuLSzL13xuIwFPghnXgj8NLx8KKFiVQL8A0gOL08Jvy4Jrx96IN+rISZERGJcrJwaEhGRNqgQiIjEOBUCEZEYp0IgIhLjVAhERGKcCoFImJk1tRip8kM7iKPUmtngliOWinQmCfveRCRm1Hro1n6RmKIWgcg+WGguiFssNB/EHDMbHl4+2MxeCw9q9qqZDQwvzzezp8Jjys83s2PCHxVvZneHx5n/d/jOUczsmvBY+h+Z2SMB7abEMBUCkU+k7nVq6KIW6yrc/TDgDuD/hZf9EXjA3ccCDwK3h5ffDsx298MJzV2wKLx8BDDD3ccAO4Dzw8uvB8aHP+fKaO2cSFt0Z7FImJlVu3t6K8tXA59z95Xhwc02uXsvMysnNGxBQ3j5RnfPNbMyoMDd61p8xmDgZXcfEX79IyDR3X9lZi8C1cDTwNP+yXj0Ih1CLQKRyHgbz/dHXYvnTXzSR3cGoXF8JgBzW4wyKdIhVAhEInNRiz/fCT9/m9BItgCXAm+En78KXAV7JhnJautDzSwOGODuM4EfERpG+DOtEpFo0m8eIp9IDc8MtduL7r77EtIcM/uI0G/108PLvg3cZ2bXAWXAl8PLrwXuMrOvEvrN/ypCI5a2Jh74v3CxMOB2D41DL9Jh1Ecgsg/hPoIidy8POotINOjUkIhIjFOLQEQkxqlFICIS41QIRERinAqBiEiMUyEQEYlxKgQiIjHu/wNRllcBbuSyrwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CODE HERE\n",
    "with torch.no_grad():\n",
    "    plt.plot(range(epochs), losses)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Cross Entropy Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl8VNX5+PHPM1mBBAIkQAiQsIR9EyKKuCAugFjQWtyqVauiVbR+rbbyq1aLXfxqrbUtLtTar9YFl7qAVRERcGMLOwECIYCEAEnYEhKyTZ7fH3PBMSaZYZncLM/79ZpX5p577sxzGTJP7jnnniOqijHGGFMXj9sBGGOMafgsWRhjjAnIkoUxxpiALFkYY4wJyJKFMcaYgCxZGGOMCciShTHGmIAsWRhjjAnIkoUxxpiAwt0O4FSJj4/XlJQUt8MwxphGZcWKFQWqmhCoXpNJFikpKaSnp7sdhjHGNCoisiOYetYMZYwxJiBLFsYYYwKyZGGMMSYgSxbGGGMCsmRhjDEmIEsWxhhjAgppshCRcSKSKSJZIvJALXWuFJENIpIhIq/5lXtFZLXzmB3KOI0xxtQtZPdZiEgYMAO4CMgBlovIbFXd4FcnFZgGjFLVAyLSwe8ljqjq0FDFd9TBknJe+noHF/TrwMCkNqF+O2OMaZRCeVPeCCBLVbMBRGQWMAnY4FfnVmCGqh4AUNW8EMZTI49H+Mv8zQCWLIwxphahbIZKAnb6bec4Zf56A71F5CsRWSIi4/z2RYtIulN+WaiCbB0dQZ+Osaz45kCo3sIYYxq9UF5ZSA1lWsP7pwKjgS7AFyIyUFUPAt1UNVdEegCficg6Vd36nTcQmQJMAejWrdsJBzosuS1zVudSVaV4PDWFbYwxzVsoryxygK5+212A3BrqvK+qFaq6DcjElzxQ1VznZzawEDit+huo6kxVTVPVtISEgPNg1Wp4t7YUlVWyJe/wCb+GMcY0ZaFMFsuBVBHpLiKRwNVA9VFN7wHnA4hIPL5mqWwRaSsiUX7lo/huX8cpNSy5LQArrSnKGGNqFLJmKFWtFJGpwFwgDHhRVTNEZDqQrqqznX0Xi8gGwAvcr6r7ROQs4HkRqcKX0B7zH0V1qqW0b0lMVDgbdxeG6i2MMaZRC+kU5ar6IfBhtbLf+D1X4F7n4V/na2BQKGPzJyL07hhD5p6i+npLY4xpVOwObkefTq3J3FuEL38ZY4zxZ8nC0adjDAdLKsgrKnM7FGOMaXAsWTj6dGoNYE1RxhhTA0sWjr6dYgHYYJ3cxhjzPZYsHG1bRZLcviUrd9jwWWOMqc6ShZ/hyW1ZseOAdXIbY0w1liz8pCW3Y19xOdv3lbgdijHGNCiWLPykpfju5F68dZ/LkRhjTMNiycJPr4QY+iW25s/zMsm3IbTGGHOMJQs/Ho/w16uHUlRaye//G7LZRYwxptGxZFFNasdYbj67O++tzmVdziG3wzHGmAbBkkUNbh/dk3atIvnDhxttZJQxxmDJokatoyO4e0wvFmfvY2FmvtvhGGOM6yxZ1OLaM5Jp3yqSOWurr9dkjDHNjyWLWkSGexie3Nbu6DbGGCxZ1Gl4clu27yuh4LANozXGNG+WLOow/Ohyq3Z1YYxp5ixZ1GFgUhsiwzws27bf7VCMMcZVlizqEB0Rxoju7Vi02UZEGWOaN0sWAYzuk8CWvMPs3G+TCxpjmq+QJgsRGScimSKSJSIP1FLnShHZICIZIvKaX/kNIrLFedwQyjjrcn7fDgAsyMxzKwRjjHFdyJKFiIQBM4DxQH/gGhHpX61OKjANGKWqA4B7nPJ2wMPAGcAI4GERaRuqWOvSI74VAzq35tmFWzlcVulGCMYY47pQXlmMALJUNVtVy4FZwKRqdW4FZqjqAQBVPfrn+1hgnqrud/bNA8aFMNZaiQjTJw1k96FSnlmQ5UYIxhjjulAmiyRgp992jlPmrzfQW0S+EpElIjLuOI5FRKaISLqIpOfnh64TenhyWyYMTuTfi3dQVFoRsvcxxpiGKpTJQmooqz4rXziQCowGrgFeEJG4II9FVWeqapqqpiUkJJxkuHW77dweFJVV8sbynYErG2NMExPKZJEDdPXb7gJUn2gpB3hfVStUdRuQiS95BHNsvRrcJY5BSW34aP0eN8MwxhhXhDJZLAdSRaS7iEQCVwOzq9V5DzgfQETi8TVLZQNzgYtFpK3TsX2xU+aq83onsHrnQQ4dsaYoY0zzErJkoaqVwFR8X/IbgTdVNUNEpovIRKfaXGCfiGwAFgD3q+o+Vd0PPIov4SwHpjtlrjq3dwLeKuXrrAK3QzHGmHolTWVxn7S0NE1PTw/pe1R4qxg2fR4X9e/In68aGtL3MsaY+iAiK1Q1LVA9u4P7OESEebh8WBJz1uayt7DU7XCMMabeWLI4Tjef3R1vlfLy4u1uh2KMMfXGksVxSm7finN7J/Deqlxbn9sY02xYsjgBlw7uzK6DR1iTc8jtUIwxpl5YsjgBF/XvSESY8N6qXW6HYowx9cKSxQlo0yKCHwzpzGtLv2F7QbHb4RhjTMhZsjhBD4zrS0SY8NSnm90OxRhjQs6SxQnq0DqaiUOT+HTDXkorvG6HY4wxIWXJ4iSMHdCR4nIvX9kd3caYJs6SxUk4q2c8sVHhvLfa1TkOjTEm5CxZnITIcA8/PjOZOWtySd/u+tRVxhgTMpYsTtJdY3rRuU00D763ngpvldvhGGNMSFiyOEmtosJ5eOIANu0p4qWvt7sdjjHGhIQli1Pg4v4dGdWrPS9+uY2qKpsCxBjT9FiyOAVEhCvTupJ7qJT0HQfcDscYY045SxanyIX9OtIiIoz3VtsUIMaYpseSxSnSKiqc8YM68d6qXRwqsWVXjTFNiyWLU+iWs3tQUu7llaU73A7FGGNOqYDJQkQeF5HWIhIhIvNFpEBErquP4Bqb/p1bc27vBF74IpvCUru6MMY0HcFcWVysqoXApUAO0Bu4P5gXF5FxIpIpIlki8kAN+28UkXwRWe08bvHb5/Urnx3k+bjul2P7cKCkgucWbnU7FGOMOWWCSRYRzs9LgNdVNahblUUkDJgBjAf6A9eISP8aqr6hqkOdxwt+5Uf8yicG854NwcCkNlw6OJF/L97B4bJKt8MxxphTIphkMUdENgFpwHwRSQBKgzhuBJClqtmqWg7MAiadeKiNx0/P7k5RWSXvrsxxOxRjjDklAiYLVX0AGAmkqWoFUExwX/pJwE6/7RynrLorRGStiLwtIl39yqNFJF1ElojIZUG8X4NxWtc4hnRpw9Pzt7BpT6Hb4RhjzEkLpoN7MlCpql4ReRB4BegcxGtLDWXVb2+eA6So6mDgU+Alv33dVDUNuBb4i4j0rCG2KU5CSc/Pzw8ipPohIjx55VDCPMJt/16B1+7qNsY0csE0Qz2kqkUicjYwFt8X+rNBHJcD+F8pdAG+M5e3qu5T1TJn8x/AcL99uc7PbGAhcFr1N1DVmaqapqppCQkJQYRUf3p1iOG3EweyY18JczP2uB2OMcaclGCSxdFl4CYAz6rq+0BkEMctB1JFpLuIRAJXA98Z1SQiiX6bE4GNTnlbEYlynscDo4ANQbxng3JR/44kt2/JHz7cyOqdB90OxxhjTlgwyWKXiDwPXAl86HyJB9PXUQlMBebiSwJvqmqGiEwXkaOjm+4WkQwRWQPcDdzolPcD0p3yBcBjqtrokkWYR3hy8hCqqpQbXlxmd3YbYxotUa27PV1EWgLjgHWqusW5Ghikqp/UR4DBSktL0/T0dLfDqNGG3EIm/O0Lppzbg2nj+7kdjjHGHCMiK5z+4ToFc4VQAmwFxorIVKBDQ0sUDV3/zq35weDOvLbkG8oqvYEPMMaYBiaY0VA/B14FOjiPV0TkrlAH1tRcPiyJorJKvsoqcDsUY4w5bsH0WdwMnKGqv1HV3wBnAreGNqym56ye7YmNCuejdTYyyhjT+ASTLIRvR0ThPK/pHgpTh6jwMC7s35G5GXsorbCmKGNM4xJMsvgXsFREHhGRR4AlwIshjaqJuvy0JApLK5m/Mc/tUIwx5riEB6qgqn8WkYXA2fiuKG5S1VWhDqwpGtUrnsQ20Tw+dxPbCg4zdUyq2yEZY0xQglr8SFVXqupfVfVpVV0lIt+EOrCmKMwj/Gx0TwqPVPCnTzaTVxjMfIzGGOO+E10pz/osTtBPRqYwa8pIAOZt3OtyNMYYE5wTTRY2M95J6N0xhpT2Lfkkw5KFMaZxqLXPQkTurW0XEBOacJoHEWHcwERe+CKb3INH6BzXwu2QjDGmTnVdWcTW8ogBng59aE3bj8/ohgIvfrnN7VCMMSagWq8sVPW39RlIc9O1XUsmDErkhS+3sT73EK/cfAbhYSfaKmiMMaFl304u+v3lA7ljdE+WZO/nw/V2Z7cxpuGyZOGi2OgI7ru4Dz0TWvHswq1U2Yp6xpgGKpiJBMPqI5DmyuMR7r4glY27C3lp8Xa3wzHGmBoFc2WRJSJPiEj/kEfTTE0c0pnRfRJ4Ym4mB0vK3Q7HGGO+J5hkMRjYDLwgIktEZIqItA5xXM2KiPCrcX0pKffyZvpOt8MxxpjvCWbxoyJV/YeqngX8EngY2C0iL4lIr5BH2Ez0S2zNGd3b8dLXOyguq3Q7HGOM+Y6g+ixEZKKIvIvv/oongR7AHODDEMfXrPz8wlT2FJZyx6srrbPbGNOgBNMMtQWYBDyhqqep6p9Vda+qvg18HNrwmpezesbzyMQBLNqcz9src9wOxxhjjgmqz0JVb1bVr6vvUNW76zpQRMaJSKaIZInIAzXsv1FE8kVktfO4xW/fDSKyxXncENTZNAHXndGNYd3iePzjTIpKK9wOxxhjgOCSRQcRmSMiBSKSJyLvi0iPQAc5Q25nAOOB/sA1tYyoekNVhzqPF5xj2+HrGzkDGAE8LCJtgz2pxkxEeGTiAAoOl/H3z7LcDscYY4DgksVrwJtAJ6Az8BbwehDHjQCyVDVbVcuBWfias4IxFpinqvtV9QAwDxgX5LGN3uAucUwe3oUXv9pGdv5ht8Mxxpjg1uBW1X+raqXzeIXgpihPAvzHgeY4ZdVdISJrReRtEel6PMc6w3jTRSQ9Pz8/iJAaj/vH9SEqPIzf/Xej26EYY0xQyWKBiDwgIikikiwivwT+KyLtnOai2tS0QFL1JDMHSFHVwcCnwEvHcSyqOlNV01Q1LSEhIYhTaTw6xEZz5/m9+GxTHpl7itwOxxjTzAWTLK4CbgMWAAuBnwE/BVYA6XUclwN09dvuAuT6V1DVfapa5mz+Axge7LHNwRXDkxCBj9bvdjsUY0wzV+sU5UepavcTfO3lQKqIdAd2AVcD1/pXEJFEVT36TTgRONrmMhf4g1+n9sXAtBOMo9HqEBtNWnJb3l21ixYRYdxyTg/CPLairTGm/gVzU16EiNzt9Cm8LSJTRSQi0HGqWglMxffFvxF4U1UzRGS6iEx0qt0tIhkisga4G7jROXY/8Ci+hLMcmO6UNTsTBiWyY18Jf/xoE19lFbgdjjGmmRLVuvuqReQFIIJv+xOuB7yqekvtR9W/tLQ0TU+vq1Wscar0VrF650FueHEZk05L4g+XD3I7JGNMEyIiK1Q1LVC9YPosTlfVG1T1M+dxE3D6yYdoghEe5iEtpR2j+3bgk4w9eG0aEGOMC4JJFl4R6Xl0w7khzxu6kExNJg7pTMHhcn4+axU/n7WKQru72xhTjwJ2cAP34xs+m41vSGsycFNIozLfc3H/jlwzoiuvL/PdfnJWz/ZcdXo3l6MyxjQXdV5ZiIgHOAKk4uuAvhvoo6oL6iE240dE+N1lg3j/zlEkxbXgk4y9bodkjGlG6kwWqloFPKmqZaq6VlXX+N0XYepZmEcY0jWOsQM68UVWASt2HHA7JGNMMxFMn8UnInKFiNgA/wZicloXwj3CFc9+zcfr97gdjjGmGQgmWdyLb/LAMhEpFJEiESkMcVymDv0SW7P0/11An46xPPrBBkorbLyBMSa0gllWNVZVPaoaqaqtnW1bg9tlsdERPDJxALsOHuG5RVvdDscY08QFcwf3/GDKTP0b2bM9EwYn8uzCrWTl2WSDxpjQqTVZiEi0M6tsvIi0PTrLrIik4FvXwjQAD07oR2x0BNe9sIz8Iht7YIwJjbquLG7DN7NsX+fn0cf7+FbAMw1AYpsW/N9Np7OnsJRZy75xOxxjTBNV6015qvo08LSI3KWqf6vHmMxxGpjUhpE92vP6sm/YuKeQX47tS0p8K7fDMsY0IcFMUf43ETkLSPGvr6ovhzAuc5x+NLwLv3hrDbnr9uAR4e/XDnM7JGNMExIwWYjIv4GewGq+nRNKAUsWDcgPhnSmqLSCzL1FzFq+k3vyiujVIdbtsIwxTUQwc0OlAf010FzmxlWR4R5uHNWdfYfLeG9VLjMWbOWpq4a6HZYxpokI5qa89UCnUAdiTo32MVFcPzKZ91fvYsaCLErKK90OyRjTBARzZREPbBCRZcCxsZmqOrH2Q4ybbj2nB19lFfDE3Ez2F5fz0KX93Q7JGNPIBZMsHgl1EObUSoiN4r93n8Mv3lzDq0t3cNt5PegQG+12WMaYRqyum/L6AqjqImCJqi46+sDvCsM0XHeN6UWFV/nr/C1uh2KMaeTq6rN4ze/54mr7ngnmxUVknIhkikiWiDxQR70fiYiKSJqznSIiR0RktfN4Lpj3M9+VEt+K689M5rWl3zDtnXU8MXcTew6Vuh2WMaYRqqsZSmp5XtP29w8WCcN3p/dFQA6wXERmq+qGavVi8S2qtLTaS2xVVRvOc5LuuTCVDbsL+SRjD/tLytlbWMafJg9xOyxjTCNT15WF1vK8pu2ajACyVDVbVcuBWcCkGuo9CjwO2J+8IRDXMpI3bxvJiocu4vozk5m9OtfmkDLGHLe6kkUXEfmriPzN7/nR7aQgXjsJ2Om3nVP9OBE5Deiqqh/UcHx3EVklIotE5Jwg3s8EcONZKZR7q3hrxc7AlY0xxk9dzVD3+z1Pr7av+nZNamqqOnZF4qzv/RRwYw31dgPdVHWfiAwH3hORAar6nUWXRGQKMAWgW7duQYTUvPVIiGFwlzZ8krGXO0b3cjscY0wjUtdEgi+d5GvnAF39trsAuX7bscBAYKGzYmsnYLaITFTVdJwRV6q6QkS2Ar2plqRUdSYwEyAtLc3uMA/CRf068uS8zcxYkMXEIZ3p2q6l2yEZYxqBYO7gPlHLgVQR6S4ikcDVwOyjO1X1kKrGq2qKqqYAS4CJqpouIglOBzki0gNIBbJDGGuzcWH/jgA8MTeTa/6xhLxC6yoyxgQWsmShqpXAVGAusBF4U1UzRGS6iAS6+/tcYK2IrAHeBm5X1f2hirU56dsplmnj+/LbiQPILyrjqU/tHgxjTGDSVOYHTEtL0/T0YLpSzFH3vrGaeRv3svzXFxIdEeZ2OMYYF4jIClVNC1QvmDW4HxeR1iISISLzRaRARK47NWEaN/1wWBeKSiuZt2Gv26EYYxq4YJqhLnZGIV2Kr9O6N98dKWUaqZE925PSviVPzdtMWaU38AHGmGYrmGQR4fy8BHjd+g6ajjCP8NtJA8kuKObZhVvdDscY04AFkyzmiMgmfIsgzReRBOxu6ybjvN4JTBzSmWcWbGVr/mGemLvJmqWMMd8TVAe3iLQFClXVKyItgdaquifk0R0H6+A+cXlFpVz45CLax0SxraCY/omt+fDndtO8Mc3BqezgngxUOoniQeAVoPMpiNE0EB1io3lgfD+2FRQDsGF3Idn5h12OyhjTkATTDPWQqhaJyNnAWOAl4NnQhmXq29Wnd+UnI5P57cQBALyRbvNHGWO+FcxKeUeHyUwAnlXV90XkkdCFZNzg8QjTJw0EYMWOAzy/KJse8a246nSbc8sYE9yVxS4ReR64EvhQRKKCPM40Un+aPIRRvdrz6AcbySssxVvVNG7cNMacuGC+9K/EN2XHOFU9CLTD7rNo0iLDPfz+skGUV1Zx8V8+Z8DDH3PNzCUcLqt0OzRjjEsCJgtVLQG2AmNFZCrQQVU/CXlkxlUp8a34541pXNy/Iz8Y3Jll2/dz9czF5BwocTs0Y4wLghkN9XPgVaCD83hFRO4KdWDGfeekJvD4j4bwxOQhzLx+ODsKSvjVf9a6HZYxxgXBNEPdDJyhqr9R1d8AZwK3hjYs09Bc0K8j141MZtm2/dYcZUwzFEyyEL4dEYXzvKZV8EwTd05qPBVeZcnWfW6HYoypZ8EMnf0XsFRE3nW2LwP+GbqQTEM1PLktLSLCmL9pL4O7tEFESIiNcjssY0w9CJgsVPXPIrIQOBvfFcVNqroq1IGZhicqPIzxgzrx+rKdvL0ih+7xrZh7z7k4y+IaY5qwOpOFiHiAtao6EFhZPyGZhuyxHw6mQ2w0K3ccYNn2/azeeZDTurV1OyxjTIjV2WehqlXAGhGx23gN4LsH44HxffnnjWlER3h406YFMaZZCKbPIhHIEJFlQPHRQlUNtI62acJioyO4YlgXXlv2DYeOVBAR5uGmUd0Z2jXO7dCMMSEQTLL4bcijMI3SgxP6k5FbyIJN+USECe+vzuWSQZ342zXDCPNYP4YxTUmtyUJEegEdVXVRtfJzgV3BvLiIjAOeBsKAF1T1sVrq/Qh4CzhdVdOdsmn47vHwAner6txg3tPUnxaRYbxx25lUehUFnl+0lb99loWwinN7x9skhMY0IXX1WfwFKKqhvMTZVycRCQNmAOOB/sA1ItK/hnqxwN3AUr+y/sDVwABgHPCM83qmgYkKD6NVVDgxUeHce1FvLhvamf+u280D76yzNTGMaULqShYpqvq9uR2cv/xTgnjtEUCWqmarajkwC5hUQ71Hgcf57lKtk4BZqlqmqtuALOf1TAMmIjx11VC+fmAMEWEenlm4lWBWYjTGNHx1JYvoOva1COK1kwD/oTI5TtkxInIa0FVVPzjeY53jp4hIuoik5+fnBxGSCTURoXNcC64d0Y23V+Rw47+WU+GtcjssY8xJqitZLBeR780BJSI3AyuCeO2aejiP/Znp3MPxFPCL4z32WIHqTFVNU9W0hISEIEIy9eXBCf349SX9WLQ5nyfmZlJs80kZ06jVNRrqHuBdEfkx3yaHNCASuDyI184BuvptdwFy/bZjgYHAQucO4E7AbBGZGMSxpoELD/Nw67k92Li7kJmfZ/Puql3MnjqKxDbBXJQaYxoaCdSmLCLn4/tSB8hQ1c+CemGRcGAzcAG+0VPLgWtVNaOW+guB+1Q1XUQGAK/h66foDMwHUlXVW9OxAGlpaZqenh5MaKYeeauURZvzmPraKtrHRJLaIZbLT0viB0M6ux2aMQYQkRWqmhaoXjBzQy0AFhxvAKpa6SyWNBff0NkXVTVDRKYD6ao6u45jM0TkTWADUAncWVeiMA1XmEcY07cjT101lOcWbWVLXhF3vb6KAZ1b0yMhxu3wjDFBCnhl0VjYlUXjsOdQKSMfm8/dY1K558JUisu9xEQFc2+oMSYUgr2yCGY9C2NOmU5tojmze3veX72LZxZu5fTffUpeYWngA40xrrJkYerddWcms31fCU/MzeRIhZe/fraFRz/YQEm5jZgypqGy639T7yYMTiT3YD/eWrGTSq/yypJvAAgPE6aN7+dydMaYmtiVhXHFref24JP/OY9rRvjmjxrSNY4XvtjGjn3FAY40xrjBkoVx1Y2jUvjo5+cw8/rhCPDPL7exNuegTRNiTANjycK4KiLMQ7/E1nRsHc34QYm8vHgHE//+FdPeWWfThBjTgFifhWkw7hrTi0NHKkiKi+b1ZTvZeaCE685I5qP1e7jtvB4M6NzG7RCNabbsPgvTIL2VvpMH31tPWaXv6iIq3MPsqWfTp1Osy5EZ07TYfRamUZuc1pUvfzWGZ348jIX3jQbgtaU73A3KmGbMkoVpsBJio7hkUCIp8a0YO6AT76/JpazSZn0xxg3WZ2EahSvTujJ7TS4/fOZrosI9nJ7SDm+VcvM53Y/NZHuguJy4lhE4sxgbY04hu7IwjcLZqfH8afIQvFWKV2HmF9m88OU2fvHmGsoqvdz9+ipOe3QeryzxNVUVl1VSVdU0+uOMaQisg9s0SiXllby7ahe/fnc9g5LasG7XIdq3iqRTm2heveUMzn18Afde1JsbR3V3O1RjGjTr4DZNWsvIcK4d0Y3Jw7uwbtchJgxOZOqYXmTkFvLYR5soLK1k/qY8t8M0psmwPgvTaIkIj10xmHN6J3Be7wQqvFX878ebmLXct3x7+vYDVHiriAjz/U1UXllFRJhYn4YxJ8CuLEyjFuYRJg7pTJsWEcTHRDFrykiGdo3jyrQuHKnw8syCrfzizTW8uyqH8/+0kN+8X+NCjcaYAKzPwjRJ+w6Xkfb7T1H1JRSvX2f3fRf35pJBibZSnzEE32dhycI0WYs259MyMozk9i255aV0xvTtwH/X7mZL3mGiwj1cNjSJK4Z34ZOMPRwuq+Rno3uS3L6V22EbU68sWRhTg0pvFbsPlfLHjzby5ZYCCkt9Cy5Fhnno0ymWOXed7XKExtSvBjEaSkTGiUimiGSJyAM17L9dRNaJyGoR+VJE+jvlKSJyxClfLSLPhTJO03yEh3no2q4lz/x4OF/8agwX9+/I7ef15P9d0pd1uw4xfc4GXl/2zbH6ryzZwd8/2+JixMY0DCEbDSUiYcAM4CIgB1guIrNVdYNftddU9Tmn/kTgz8A4Z99WVR0aqviMadMigpk/8f1Bdaikgj98tIkXv9oGwLaCYu48vxd/+XQzRaWV3Hx2D1pEhrkZrjGuCuXQ2RFAlqpmA4jILGAScCxZqGqhX/1WQNNoEzONTpuWETx0aX/KKrxs2XuYmZ9n887KXRQcLgdgcXYBY/p2pNJbRVllFa2ibNS5aV5C+T8+Cdjpt50DnFG9kojcCdwLRAJj/HZ1F5FVQCHwoKp+EcJYjeH6M5OPPR/TrwO3/XsFkeEewj3COyt3ER8TxUPvrWfXwVLevO1MG01lmpWQdXCLyGRgrKre4mxfD4xQ1btqqX+tU/8GEYkCYlR1n4gMB94DBlS7EkFEpgBTALp16zZ8xw6bwtqcOn+dvwVvlZKVf5iEtvkGAAARkklEQVT/rt0N+NbVaBkZRquocP514+mUVVYxMMkWZTKNl+ujoURkJPCIqo51tqcBqOofa6nvAQ6o6vd+80RkIXCfqtY63MlGQ5lQKa3wsjbnEPuLy+jdMZaDRyqY/NxivFVKZJiHf988gvfX5FJ4pIJfT+h3bBbc0gov0RHWz2EatmCTRSiboZYDqSLSHdgFXA1c619BRFJV9ehQkwnAFqc8Adivql4R6QGkAtkhjNWYWkVHhDGie7vvlD38g/7M35jH4ux9XDVzCdERHjwifL11Hw9d2o/tBSX8fUEWAzu3JjoijNtH96RLXAtSO9pKf6ZxCul9FiJyCfAXIAx4UVV/LyLTgXRVnS0iTwMXAhXAAWCqqmaIyBXAdKAS8AIPq+qcut7LriyMG578JJO30nN46acjCPMI9721htU7DwIwPLktEWHCjn0l7D5UCsDoPgkkxbVg/MBEzk6Np9Jbxa6DR+jWrqXNWWVc4XozVH2zZGHcoKpUOVOKAHirlFeX7mDFjgP88YeDaBkZTlFpBV9v3UdGbiFvLP+G4jIvh8squfy0JBZv3ceewlJG9mjPpUMSmTy8K5HhNmWbqT+WLIxpoMoqvUz7zzreWbWLYd3iOCc1gdeWfUN+URl3jO7JL8f1peBwGe+u3MUVw7vQrlWk2yGbJqwh9FkYY2oQFR7GE5OHcNOo7gzo3BqPR7jnwlR++fZanv88m1ZR4Ty/aCuFpZV8mVXAvRf1ZvPeIi4e0IntBcXEx0bRMTaKxz7axPhBiQxPbuv2KZlmwK4sjGkgDh2p4McvLGH9rkJSO8Rw8YCOzFiw9dj+7vGt2FZQDMDpKW1Zvv0ASXEtmPs/5xJjNwmaE2TNUMY0QsVllbyVvpOJQ5No2zKCRZvzKausYteBI0z/YANn94qnQ2wU76zadSx5eAQ8IqR2jOXhH/RnSJc4osI9eDw1d5jvO1yGR4S21rxlsGRhTJOzeudB+naKJSLMw6tLd3B+nw5s31fM8m37Kfcqc9bk4vH4VgRMbNOC689MZtOeQtq1iqJNiwiGJ7eld8cYxj/9BflFZbx66xn07dTa7dMyLrNkYUwzM2/DXm59Of3YFCUl5V4iwzyUe6sAiIkK51fj+vDQ+xlEhnlIjItm3v+c953RV3PW5JKdX8zPL0x16zRMPbMObmOamQv7deD6M5M5vXs7RvVsz8EjFXRp24L9xeXkF5Ux5eUVPPR+Bq0ifR3sd7y6kqc+3cwtZ3enbctINuwu5L631lBWWcXInu2P3Yh4sKScnANHbFqTZs6uLIxpJvYWlvKXT7fQt1MsPxmZzK0vp/PpxjwAIsM9lFdWERsdTouIMOJjorh9dE+25RczN2MPmXuLeP/OUfRMiCGvqJT4mCg27C4kJiqcTzfs5WejexIeZveHNEbWDGWMqVOlt4q1uw7xdVYBh45U0K1dS0b1iic7v5jbX1lBpd+65W1aRBATFY7HA7kHS+nbKZaM3EIiwoQKr/L7ywdyTq8EEmKjqKyqYuPuIgZ3afOdubGOlHuJjvDYneoNjCULY8wJ+yqrgIzcQ4zsEc+BknKiI8L43483UeGt4nBZJdn5xUwYlEjB4TKKyytZv+vbCaHDPIK3SomJCmfcwE7ce1Fvcg8e4crnF9M+Jopbz+nODWelEBVukyw2BJYsjDEhsbewlJU7DjBuYCdEhI27C3l+0VbSUtpx6EgFh8sqGdC5NYsy8/lg7W7CPULXdi3ZfegIg7rE8fnmfJLbt2T6pIG8vSKHu8f04qusAhZk5nNlWlcmDE4kr6iUJ+du5pozujG0axwLM/Po26k1ndpEu336TY4lC2OM677ZV8KN/7eM7Pxi7rkwlXsu7M3nm/O5/+017C0sA6BDbBR5RWW0bxXJvuJyWkaGUeGtosKrnNmjHef2TuDxjzPp1q4l//nZWby1Yidpye2OdcC/vHg7Xdu25Py+HQLGc6ikguLySjrHtQjlaTcqliyMMQ1C7sEjvLR4O3eM7kWbFhEAZO4pYto7a4mPieKTDXs5rVscr996Ji8v3k5eYRkiUFzu5bWl3wBwXu8Elm3bT2x0OHlFZSTFteCz+85j5/4jXPTUInolxDDv3vP4emsBbVtG0i/x+/ePqCqTn1vM3qJSPr//fOs7cViyMMY0eIfLKvnDhxu56ayU7631cbCknAueXMSoXvH8+cohfL4ln1tfXkHnuGh27j/COanxFJZWssaZEn7cgE58nLGHpLgWfHTPOTw6ZwMHj1Twi4t707dTaz7btJef/p/vO+KWs7uzfV8x917Uh/6d674xMXNPES9+uY1rz+jGkK5xofmHcJElC2NMo1d9tcHMPUV0jovm759l8cHa3Ryp8HL5aUn866ttVCmc3yeBBZn5tG8Vyf6ScmKjwlGFGT8exrR31lHhrSKvqOzY68VGh7PgvtF8uaWATXuKuOr0rnSPb/WdGK7/51K+2FJAmEd4946zGNwljt2HjvCfFTkMTGrDeb0T2FdcTpsWEXy4bjeXDEokohENI7ZkYYxpNv734020jAhj6pheXDVzCbsOHOF3lw2kT6dYLpvxFXlFZUSGeXjr9pH8zxuryS4o5o8/HMSD762ndXQ4B0oqABCBy4Ym8esJ/Xh58Q4Wbc5nzc6D3DG6J2+tyKFT62juG9uHaf9ZS66zoNUFfTswf1Me56TG88WWAv40eQhXDEsKupnrUEkF2QWH6ZfY2pVleC1ZGGOapUpvFR6RYxMp7jlUyueb8+mbGMvgLnG8+OU2Vu88yNNXD+UPH27k3VW7+OXYvozuk8A/v9rGzM+z8Yhv+O/gLm3wiPDKLWfw+eZ87nxtJaqQ2CaaZ68bzu//u4Hl2w985/1TO8Swv7gcEeGJyYM5v8+3He/f7CshJjqcdq0iOVLu5bGPNvL6sp2Ue6u4YWQyv500EPDN73Xjv5ZxWrc47h/bN6T/XpYsjDEmgKPff/5XAbPX5DJnTS53jO7Jad2+u1bI1vzDrNxxgEsGJdIqKpxv9pXw9wVbGD8wkb/M30JCTCSfbsyjQ2wUbVtGsvNACZcMSkSAqAgPryzxddif1bM9ewpL2VZQzNWndyOvsJTF2ftYPO0CNu8t4t1Vu4517v90VHc27y2iW/uWPDihH5FhHp5duJWOraO58vSuJ/1vYMnCGGPq2aY9hVw24ytmXDuMgUltuP/ttWTuKaTSq+wrLueSQZ3o1SGWOWtyadsygrvGpHJ+3w5k5B5iwl+/pG+nWDbtKQJg7ICOqMK8jXtp3yqKfcVlJLaOJs6Zxysy3MOUc3qwv6ScSwcnclbP+BOK2ZKFMca4wFulx9ZkP0rVlyzat4qstS9j5udbmbV8J2f3iuf6M5Pp1r4lUeFhHC6rJDrcw8pvDvLE3E2UV1bxgyGdeXxuJuWVVUSGe+if2Jr37hx1QvE2iGQhIuOAp4Ew4AVVfaza/tuBOwEvcBiYoqobnH3TgJudfXer6ty63suShTGmOXlv1S5Kyn2jwfYWlpJSbRRXsFxPFiISBmwGLgJygOXANUeTgVOntaoWOs8nAneo6jgR6Q+8DowAOgOfAr1V1Vvb+1myMMaY4xdssgjlYOARQJaqZqtqOTALmORf4WiicLQCjmauScAsVS1T1W1AlvN6xhhjXBDKxY+SgJ1+2znAGdUricidwL1AJDDG79gl1Y5NquHYKcAUgG7dup2SoI0xxnxfKK8saurF+V6bl6rOUNWewK+AB4/z2JmqmqaqaQkJCScVrDHGmNqFMlnkAP6DgLsAuXXUnwVcdoLHGmOMCaFQJovlQKqIdBeRSOBqYLZ/BRHxXxV+ArDFeT4buFpEokSkO5AKLAthrMYYY+oQsj4LVa0UkanAXHxDZ19U1QwRmQ6kq+psYKqIXAhUAAeAG5xjM0TkTWADUAncWddIKGOMMaFlN+UZY0wz1hCGzhpjjGkimsyVhYjkAztO4iXigYJTFI7bmsq5NJXzADuXhsrOBZJVNeBw0iaTLE6WiKQHcynWGDSVc2kq5wF2Lg2VnUvwrBnKGGNMQJYsjDHGBGTJ4lsz3Q7gFGoq59JUzgPsXBoqO5cgWZ+FMcaYgOzKwhhjTEDNPlmIyDgRyRSRLBF5wO14jpeIbBeRdSKyWkTSnbJ2IjJPRLY4P9sGeh03iMiLIpInIuv9ymqMXXz+6nxOa0VkmHuRf18t5/KIiOxyPpvVInKJ375pzrlkishYd6KumYh0FZEFIrJRRDJE5OdOeaP6bOo4j0b3uYhItIgsE5E1zrn81invLiJLnc/kDWdqJZypkt5wzmWpiKScdBCq2mwf+KYh2Qr0wDdF+hqgv9txHec5bAfiq5U9DjzgPH8A+F+346wl9nOBYcD6QLEDlwAf4ZuR+ExgqdvxB3EujwD31VC3v/N/LQro7vwfDHP7HPziSwSGOc9j8S1i1r+xfTZ1nEej+1ycf9sY53kEsNT5t34TuNopfw74mfP8DuA55/nVwBsnG0Nzv7IIuEBTIzUJeMl5/hLfzubboKjq58D+asW1xT4JeFl9lgBxIpJYP5EGVsu51KZBL+6lqrtVdaXzvAjYiG89mUb12dRxHrVpsJ+L82972NmMcB6Kbw2gt53y6p/J0c/qbeACqW3x7yA192RR0wJNdf1naogU+EREVjiLQQF0VNXd4PuFATq4Ft3xqy32xvpZTXWaZl70aw5sNOfiNF+chu8v2Ub72VQ7D2iEn4uIhInIaiAPmIfvyuegqlY6VfzjPXYuzv5DQPuTef/mniyCWmSpgRulqsOA8cCdInKu2wGFSGP8rJ4FegJDgd3Ak055ozgXEYkB/gPco99dAvl7VWsoazDnU8N5NMrPRVW9qjoU3/o+I4B+NVVzfp7yc2nuyaLRL7KkqrnOzzzgXXz/ifYebQZwfua5F+Fxqy32RvdZqepe5xe8CvgH3zZpNPhzEZEIfF+wr6rqO05xo/tsajqPxvy5AKjqQWAhvj6LOBE5utSEf7zHzsXZ34bgm0lr1NyTRcAFmhoyEWklIrFHnwMXA+vxncMNTrUbgPfdifCE1Bb7bOAnzsibM4FDR5tEGqpq7faX4/tsoIEv7uW0bf8T2Kiqf/bb1ag+m9rOozF+LiKSICJxzvMWwIX4+mAWAD9yqlX/TI5+Vj8CPlOnt/uEud3L7/YD30iOzfja/37tdjzHGXsPfKM31gAZR+PH1zY5H9/Kg/OBdm7HWkv8r+NrBqjA95fQzbXFju+yeobzOa0D0tyOP4hz+bcT61rnlzfRr/6vnXPJBMa7HX+1czkbX5PFWmC187iksX02dZxHo/tcgMHAKifm9cBvnPIe+BJaFvAWEOWURzvbWc7+Hicbg93BbYwxJqDm3gxljDEmCJYsjDHGBGTJwhhjTECWLIwxxgRkycIYY0xAliyMaQBEZLSIfOB2HMbUxpKFMcaYgCxZGHMcROQ6Z12B1SLyvDO522EReVJEVorIfBFJcOoOFZElzoR17/qt/9BLRD511iZYKSI9nZePEZG3RWSTiLx6srOEGnMqWbIwJkgi0g+4Ct/kjUMBL/BjoBWwUn0TOi4CHnYOeRn4laoOxnfH8NHyV4EZqjoEOAvfnd/gmxX1HnzrKvQARoX8pIwJUnjgKsYYxwXAcGC580d/C3yT6VUBbzh1XgHeEZE2QJyqLnLKXwLecubySlLVdwFUtRTAeb1lqprjbK8GUoAvQ39axgRmycKY4AnwkqpO+06hyEPV6tU1h05dTUtlfs+92O+naUCsGcqY4M0HfiQiHeDYmtTJ+H6Pjs78eS3wpaoeAg6IyDlO+fXAIvWtp5AjIpc5rxElIi3r9SyMOQH2l4sxQVLVDSLyIL6VCT34Zpi9EygGBojICnwrkl3lHHID8JyTDLKBm5zy64HnRWS68xqT6/E0jDkhNuusMSdJRA6raozbcRgTStYMZYwxJiC7sjDGGBOQXVkYY4wJyJKFMcaYgCxZGGOMCciShTHGmIAsWRhjjAnIkoUxxpiA/j8mZZVNlRHmAQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DON'T WRITE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Evaluate the test set\n",
    "With torch set to <tt>no_grad</tt>, pass <tt>cat_test</tt> and <tt>con_test</tt> through the trained model. Create a validation set called \"y_val\". Compare the output to <tt>y_test</tt> using the loss function defined above. Results may vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6851,  1.1705],\n",
       "        [-0.1143, -1.2384],\n",
       "        [-0.4627,  0.1392],\n",
       "        ...,\n",
       "        [-1.1462,  1.8326],\n",
       "        [ 1.1737, -0.5763],\n",
       "        [-1.5369,  0.6696]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE Loss: 0.31804401\n"
     ]
    }
   ],
   "source": [
    "# CODE HERE\n",
    "with torch.no_grad():\n",
    "    y_val = model(cat_test, con_test)\n",
    "    loss = criterion(y_val, y_test)\n",
    "\n",
    "# RUN THIS CODE TO COMPARE RESULTS\n",
    "print(f'CE Loss: {loss:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE Loss: 0.30774996\n"
     ]
    }
   ],
   "source": [
    "# TO EVALUATE THE TEST SET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. Calculate the overall percent accuracy\n",
    "Using a for loop, compare the argmax values of the <tt>y_val</tt> validation set to the <tt>y_test</tt> set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4276 out of 5000 = 85.52% correct\n"
     ]
    }
   ],
   "source": [
    "# CODE HERE\n",
    "\n",
    "acc = 0\n",
    "\n",
    "for i in range(len(y_val)):\n",
    "    if y_val[i].argmax() == y_test[i]:\n",
    "        acc += 1\n",
    "\n",
    "\n",
    "print(f\"{acc} out of {len(y_test)} = {100*acc/len(y_test)}% correct\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4255 out of 5000 = 85.10% correct\n"
     ]
    }
   ],
   "source": [
    "# DON'T WRITE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS: Feed new data through the trained model\n",
    "See if you can write a function that allows a user to input their own values, and generates a prediction.<br>\n",
    "<strong>HINT</strong>:<br>There's no need to build a DataFrame. You can use inputs to populate column variables, convert them to embeddings with a context dictionary, and pass the embedded values directly into the tensor constructors:<br>\n",
    "<pre>mar = input(\"What is the person's marital status? \")\n",
    "mar_d = dict(Divorced=0, Married=1, Married-spouse-absent=2, Never-married=3, Separated=4, Widowed=5)\n",
    "mar = mar_d[mar]\n",
    "cats = torch.tensor([..., ..., mar, ..., ...], dtype=torch.int64).reshape(1,-1)</pre>\n",
    "Make sure that names are put in alphabetical order before assigning numbers.\n",
    "\n",
    "Also, be sure to run <tt>model.eval()</tt> before passing new date through. Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Adm-clerical': 0,\n",
       " 'Craft-repair': 1,\n",
       " 'Exec-managerial': 2,\n",
       " 'Farming-fishing': 3,\n",
       " 'Handlers-cleaners': 4,\n",
       " 'Machine-op-inspct': 5,\n",
       " 'Other-service': 6,\n",
       " 'Prof-specialty': 7,\n",
       " 'Protective-serv': 8,\n",
       " 'Sales': 9,\n",
       " 'Tech-support': 10,\n",
       " 'Transport-moving': 11}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = {}\n",
    "for ix, i in enumerate(df['occupation'].cat.categories):\n",
    "    p[i] = ix\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'hours-per-week']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE HERE:\n",
    "\n",
    "def test_model(model):\n",
    "    age = int(input(\"What is the person's age? (18-90)  \"))\n",
    "    sex = input(\"What is the person's sex? (Male/Female) \").capitalize()\n",
    "    edu_level = int(input(\"What is the person's education level? (3-16)  \"))\n",
    "    marital_status = input(\"What is the person's marital status? \").capitalize()\n",
    "    workclass = input(\"What is the person's workclass? \").capitalize()\n",
    "    occup = input(\"What is the person's occupation?  \").capitalize()\n",
    "    work_hours = int(input(\"How many hours/week are worked? (20-90)  \"))\n",
    "    \n",
    "    marital_status_mapping = {'Divorced': 0, \n",
    "                              'Married': 1, \n",
    "                              'Married-spouse-absent': 2, \n",
    "                              'Never-married': 3, \n",
    "                              'Separated': 4, \n",
    "                              'Widowed': 5}\n",
    "\n",
    "    sex_mapping = {\"Male\": 1, \"Female\": 0}\n",
    "    \n",
    "   \n",
    "    workclass_mapping = {'Federal-gov': 0, 'Local-gov': 1, 'Private': 2, 'Self-emp': 3, 'State-gov': 4}\n",
    "    \n",
    "    occupation_mapping = {'Adm-clerical': 0, \n",
    "                          'Craft-repair': 1, \n",
    "                          'Exec-managerial': 2, \n",
    "                          'Farming-fishing': 3, \n",
    "                          'Handlers-cleaners': 4, \n",
    "                          'Machine-op-inspct': 5, \n",
    "                          'Other-service': 6, \n",
    "                          'Prof-specialty': 7, \n",
    "                          'Protective-serv': 8, \n",
    "                          'Sales': 9, \n",
    "                          'Tech-support': 10, \n",
    "                          'Transport-moving': 11}\n",
    "\n",
    "    cats = torch.tensor([sex_mapping[sex], \n",
    "                         edu_level, \n",
    "                         marital_status_mapping[marital_status], \n",
    "                         workclass_mapping[workclass], \n",
    "                         occupation_mapping[occup]], dtype=torch.int64).reshape(1,-1)\n",
    "    \n",
    "    conts = torch.tensor([age, work_hours], dtype=torch.float32).reshape(1, -1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        z = model(cats, conts)\n",
    "\n",
    "    print(f'\\nThe predicted label is {z.argmax()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the person's age? (18-90)  22\n",
      "What is the person's sex? (Male/Female) male\n",
      "What is the person's education level? (3-16)  12\n",
      "What is the person's marital status? married\n",
      "What is the person's workclass? private\n",
      "What is the person's occupation?  sales\n",
      "How many hours/week are worked? (20-90)  40\n",
      "\n",
      "The predicted label is 0\n"
     ]
    }
   ],
   "source": [
    "# RUN YOUR CODE HERE:\n",
    "model.eval()\n",
    "test_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the person's age? (18-90)  22\n",
      "What is the person's sex? (Male/Female) male\n",
      "What is the person's education level? (3-16) 12\n",
      "What is the person's marital status? married\n",
      "What is the person's workclass? private\n",
      "What is the person's occupation? sales\n",
      "How many hours/week are worked? (20-90)  40\n",
      "\n",
      "The predicted label is 0\n"
     ]
    }
   ],
   "source": [
    "# DON'T WRITE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Great job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
